{"cells":[{"cell_type":"markdown","metadata":{"id":"TH32rzgprvgM"},"source":["# Import requirements"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:14:46.404129Z","iopub.status.busy":"2022-03-27T12:14:46.403636Z","iopub.status.idle":"2022-03-27T12:14:55.485692Z","shell.execute_reply":"2022-03-27T12:14:55.484794Z","shell.execute_reply.started":"2022-03-27T12:14:46.404037Z"},"id":"G9EvC1HBuf41","trusted":true},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:14:55.487846Z","iopub.status.busy":"2022-03-27T12:14:55.487595Z","iopub.status.idle":"2022-03-27T12:15:01.276436Z","shell.execute_reply":"2022-03-27T12:15:01.275715Z","shell.execute_reply.started":"2022-03-27T12:14:55.487814Z"},"id":"AAdLxrUZrvgP","trusted":true},"outputs":[],"source":["import os\n","import pdb\n","import argparse\n","from dataclasses import dataclass, field\n","from typing import Optional\n","from collections import defaultdict\n","\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","\n","import numpy as np\n","from tqdm import tqdm, trange\n","\n","from transformers import (\n","    BertForSequenceClassification,\n","    BertTokenizer,\n","    AutoConfig,\n","    AdamW\n",")"]},{"cell_type":"markdown","metadata":{"id":"ASWOOmXqrvgQ"},"source":["# 1. Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:16:15.509657Z","iopub.status.busy":"2022-03-27T12:16:15.509275Z","iopub.status.idle":"2022-03-27T12:16:15.515658Z","shell.execute_reply":"2022-03-27T12:16:15.515161Z","shell.execute_reply.started":"2022-03-27T12:16:15.509614Z"},"id":"RAnU6w29rvgR","trusted":true},"outputs":[],"source":["def make_id_file(task, tokenizer):\n","    def make_data_strings(file_name):\n","        data_strings = []\n","        #files are ASCII .txt files\n","        with open(os.path.join('../input/goorm-nlp-projects-3rd', file_name), 'r', encoding='utf-8') as f:\n","            id_file_data = [tokenizer.encode(line.lower()) for line in f.readlines()] #make list of lines with string elements \n","            #change data that can be intepreted as with a tokenizer given\n","            #all lines are ASCII -> tokenizer encoded -> returns a list of integers \n","        for item in id_file_data:\n","            data_strings.append(' '.join([str(k) for k in item])) #changes integers to string\n","        return data_strings\n","    \n","    print('it will take some times...')\n","    train_pos = make_data_strings('sentiment.train.1')\n","    train_neg = make_data_strings('sentiment.train.0')\n","    dev_pos = make_data_strings('sentiment.dev.1')\n","    dev_neg = make_data_strings('sentiment.dev.0')\n","\n","    print('make id file finished!')\n","    return train_pos, train_neg, dev_pos, dev_neg"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:16:15.517132Z","iopub.status.busy":"2022-03-27T12:16:15.516736Z","iopub.status.idle":"2022-03-27T12:16:16.744583Z","shell.execute_reply":"2022-03-27T12:16:16.743774Z","shell.execute_reply.started":"2022-03-27T12:16:15.517069Z"},"trusted":true},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:16:16.746173Z","iopub.status.busy":"2022-03-27T12:16:16.74595Z","iopub.status.idle":"2022-03-27T12:19:10.776426Z","shell.execute_reply":"2022-03-27T12:19:10.775751Z","shell.execute_reply.started":"2022-03-27T12:16:16.746145Z"},"id":"BAgztXIBrvgS","outputId":"f4ba730a-2280-452c-d793-b80db0482b13","trusted":true},"outputs":[],"source":["train_pos, train_neg, dev_pos, dev_neg = make_id_file('yelp', tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:19:10.77753Z","iopub.status.busy":"2022-03-27T12:19:10.777334Z","iopub.status.idle":"2022-03-27T12:19:10.783427Z","shell.execute_reply":"2022-03-27T12:19:10.782983Z","shell.execute_reply.started":"2022-03-27T12:19:10.777507Z"},"id":"wRh2WjGRrvgS","outputId":"252fae0f-6d01-43f8-9c76-0cf452f176bf","trusted":true},"outputs":[],"source":["train_pos[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:19:10.785193Z","iopub.status.busy":"2022-03-27T12:19:10.784669Z","iopub.status.idle":"2022-03-27T12:19:10.795414Z","shell.execute_reply":"2022-03-27T12:19:10.794923Z","shell.execute_reply.started":"2022-03-27T12:19:10.785168Z"},"id":"JdpQQQMUrvgT","trusted":true},"outputs":[],"source":["class SentimentDataset(object):\n","    def __init__(self, tokenizer, pos, neg):\n","        self.tokenizer = tokenizer\n","        self.data = []\n","        self.label = []\n","\n","        for pos_sent in pos:\n","            self.data += [self._cast_to_int(pos_sent.strip().split())]\n","            self.label += [[1]]\n","        for neg_sent in neg:\n","            self.data += [self._cast_to_int(neg_sent.strip().split())]\n","            self.label += [[0]]\n","\n","    def _cast_to_int(self, sample):\n","        return [int(word_id) for word_id in sample]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        sample = self.data[index]\n","        return np.array(sample), np.array(self.label[index])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:19:10.797166Z","iopub.status.busy":"2022-03-27T12:19:10.796689Z","iopub.status.idle":"2022-03-27T12:19:13.766219Z","shell.execute_reply":"2022-03-27T12:19:13.765377Z","shell.execute_reply.started":"2022-03-27T12:19:10.797131Z"},"id":"wCz5ey8xrvgU","trusted":true},"outputs":[],"source":["train_dataset = SentimentDataset(tokenizer, train_pos, train_neg)\n","dev_dataset = SentimentDataset(tokenizer, dev_pos, dev_neg)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:19:13.767917Z","iopub.status.busy":"2022-03-27T12:19:13.7676Z","iopub.status.idle":"2022-03-27T12:19:13.77814Z","shell.execute_reply":"2022-03-27T12:19:13.777286Z","shell.execute_reply.started":"2022-03-27T12:19:13.767878Z"},"id":"UuvkMczvrvgU","outputId":"4f6502d4-9825-47ee-c1b9-e4375bb3fd3b","trusted":true},"outputs":[],"source":["for i, item in enumerate(train_dataset):\n","    print(item)\n","    if i == 10:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:19:13.779403Z","iopub.status.busy":"2022-03-27T12:19:13.779204Z","iopub.status.idle":"2022-03-27T12:19:13.78771Z","shell.execute_reply":"2022-03-27T12:19:13.787072Z","shell.execute_reply.started":"2022-03-27T12:19:13.779378Z"},"id":"B0wRUBYSrvgU","trusted":true},"outputs":[],"source":["def collate_fn_style(samples):\n","    input_ids, labels = zip(*samples)\n","    max_len = max(len(input_id) for input_id in input_ids)\n","    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n","    \n","    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n","                             batch_first=True)\n","    attention_mask = torch.tensor(\n","        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n","         sorted_indices])\n","    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n","    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n","    labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n","\n","    return input_ids, attention_mask, token_type_ids, position_ids, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:19:13.78894Z","iopub.status.busy":"2022-03-27T12:19:13.788637Z","iopub.status.idle":"2022-03-27T12:19:13.798599Z","shell.execute_reply":"2022-03-27T12:19:13.798064Z","shell.execute_reply.started":"2022-03-27T12:19:13.788915Z"},"id":"5saagig0rvgV","trusted":true},"outputs":[],"source":["train_batch_size=32\n","eval_batch_size=64\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size=train_batch_size,\n","                                           shuffle=True, collate_fn=collate_fn_style,\n","                                           pin_memory=True, num_workers=2)\n","dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=eval_batch_size,\n","                                         shuffle=False, collate_fn=collate_fn_style,\n","                                         num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:19:13.799851Z","iopub.status.busy":"2022-03-27T12:19:13.799538Z","iopub.status.idle":"2022-03-27T12:19:25.573462Z","shell.execute_reply":"2022-03-27T12:19:25.572723Z","shell.execute_reply.started":"2022-03-27T12:19:13.799819Z"},"id":"zvFqCaCnrvgW","trusted":true},"outputs":[],"source":["# random seed\n","random_seed=42\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:19:25.577186Z","iopub.status.busy":"2022-03-27T12:19:25.576752Z","iopub.status.idle":"2022-03-27T12:19:25.589218Z","shell.execute_reply":"2022-03-27T12:19:25.58793Z","shell.execute_reply.started":"2022-03-27T12:19:25.577145Z"},"id":"dWwhmyMyrvgW","trusted":true},"outputs":[],"source":["model.train()\n","learning_rate = 5e-5\n","optimizer = AdamW(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:19:25.591599Z","iopub.status.busy":"2022-03-27T12:19:25.590992Z","iopub.status.idle":"2022-03-27T12:19:25.595422Z","shell.execute_reply":"2022-03-27T12:19:25.594875Z","shell.execute_reply.started":"2022-03-27T12:19:25.59157Z"},"id":"MztU-L83rvgW","trusted":true},"outputs":[],"source":["def compute_acc(predictions, target_labels):\n","    return (np.array(predictions) == np.array(target_labels)).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-27T12:19:25.597007Z","iopub.status.busy":"2022-03-27T12:19:25.59676Z","iopub.status.idle":"2022-03-27T13:01:59.334697Z","shell.execute_reply":"2022-03-27T13:01:59.333004Z","shell.execute_reply.started":"2022-03-27T12:19:25.596977Z"},"id":"DuZfvzpGrvgW","outputId":"369b53a1-1927-4a51-a19c-cc2d2730fdff","trusted":true},"outputs":[],"source":["train_epoch = 3\n","lowest_valid_loss = 9999.\n","for epoch in range(train_epoch):\n","    with tqdm(train_loader, unit=\"batch\") as tepoch:\n","        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n","            tepoch.set_description(f\"Epoch {epoch}\")\n","            input_ids = input_ids.to(device)\n","            attention_mask = attention_mask.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            position_ids = position_ids.to(device)\n","            labels = labels.to(device, dtype=torch.long)\n","\n","            optimizer.zero_grad()\n","\n","            output = model(input_ids=input_ids,\n","                           attention_mask=attention_mask,\n","                           token_type_ids=token_type_ids,\n","                           position_ids=position_ids,\n","                           labels=labels)\n","\n","            loss = output.loss\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","            tepoch.set_postfix(loss=loss.item())\n","            if iteration != 0 and iteration % int(len(train_loader) / 5) == 0:\n","                # Evaluate the model five times per epoch\n","                with torch.no_grad():\n","                    model.eval()\n","                    valid_losses = []\n","                    predictions = []\n","                    target_labels = []\n","                    for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n","                                                                                                desc='Eval',\n","                                                                                                position=1,\n","                                                                                                leave=None):\n","                        input_ids = input_ids.to(device)\n","                        attention_mask = attention_mask.to(device)\n","                        token_type_ids = token_type_ids.to(device)\n","                        position_ids = position_ids.to(device)\n","                        labels = labels.to(device, dtype=torch.long)\n","\n","                        output = model(input_ids=input_ids,\n","                                       attention_mask=attention_mask,\n","                                       token_type_ids=token_type_ids,\n","                                       position_ids=position_ids,\n","                                       labels=labels)\n","\n","                        logits = output.logits\n","                        loss = output.loss\n","                        valid_losses.append(loss.item())\n","\n","                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n","                        batch_labels = [int(example) for example in labels]\n","\n","                        predictions += batch_predictions\n","                        target_labels += batch_labels\n","\n","                acc = compute_acc(predictions, target_labels)\n","                valid_loss = sum(valid_losses) / len(valid_losses)\n","                if lowest_valid_loss > valid_loss:\n","                    print('Acc for model which have lower valid loss: ', acc)\n","                    torch.save(model.state_dict(), \"./pytorch_model.bin\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.336973Z","iopub.status.idle":"2022-03-27T13:01:59.337722Z","shell.execute_reply":"2022-03-27T13:01:59.337463Z","shell.execute_reply.started":"2022-03-27T13:01:59.337435Z"},"id":"P95gtlnurvgX","trusted":true},"outputs":[],"source":["import pandas as pd\n","test_df = pd.read_csv('test_no_label.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.339279Z","iopub.status.idle":"2022-03-27T13:01:59.340039Z","shell.execute_reply":"2022-03-27T13:01:59.339787Z","shell.execute_reply.started":"2022-03-27T13:01:59.339757Z"},"id":"cLDzC10ErvgX","trusted":true},"outputs":[],"source":["test_dataset = test_df['Id']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.341511Z","iopub.status.idle":"2022-03-27T13:01:59.342218Z","shell.execute_reply":"2022-03-27T13:01:59.341988Z","shell.execute_reply.started":"2022-03-27T13:01:59.341962Z"},"id":"jnt693N0rvgX","trusted":true},"outputs":[],"source":["def make_id_file_test(tokenizer, test_dataset):\n","    data_strings = []\n","    id_file_data = [tokenizer.encode(sent.lower()) for sent in test_dataset]\n","    for item in id_file_data:\n","        data_strings.append(' '.join([str(k) for k in item]))\n","    return data_strings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.343307Z","iopub.status.idle":"2022-03-27T13:01:59.343971Z","shell.execute_reply":"2022-03-27T13:01:59.343817Z","shell.execute_reply.started":"2022-03-27T13:01:59.343785Z"},"id":"7C5PpXtlrvgY","trusted":true},"outputs":[],"source":["test = make_id_file_test(tokenizer, test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.34492Z","iopub.status.idle":"2022-03-27T13:01:59.345382Z","shell.execute_reply":"2022-03-27T13:01:59.345235Z","shell.execute_reply.started":"2022-03-27T13:01:59.345217Z"},"id":"1aqse7SHrvgY","trusted":true},"outputs":[],"source":["test[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.346283Z","iopub.status.idle":"2022-03-27T13:01:59.34664Z","shell.execute_reply":"2022-03-27T13:01:59.34649Z","shell.execute_reply.started":"2022-03-27T13:01:59.346466Z"},"id":"cZi14gnnrvgY","trusted":true},"outputs":[],"source":["class SentimentTestDataset(object):\n","    def __init__(self, tokenizer, test):\n","        self.tokenizer = tokenizer\n","        self.data = []\n","\n","        for sent in test:\n","            self.data += [self._cast_to_int(sent.strip().split())]\n","\n","    def _cast_to_int(self, sample):\n","        return [int(word_id) for word_id in sample]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        sample = self.data[index]\n","        return np.array(sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.348133Z","iopub.status.idle":"2022-03-27T13:01:59.348437Z","shell.execute_reply":"2022-03-27T13:01:59.348295Z","shell.execute_reply.started":"2022-03-27T13:01:59.348274Z"},"id":"erHjGE9rrvgY","trusted":true},"outputs":[],"source":["test_dataset = SentimentTestDataset(tokenizer, test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.349649Z","iopub.status.idle":"2022-03-27T13:01:59.349981Z","shell.execute_reply":"2022-03-27T13:01:59.349835Z","shell.execute_reply.started":"2022-03-27T13:01:59.349793Z"},"id":"y03-nDX9rvgZ","trusted":true},"outputs":[],"source":["def collate_fn_style_test(samples):\n","    input_ids = samples\n","    max_len = max(len(input_id) for input_id in input_ids)\n","    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n","    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n","                             batch_first=True)\n","    attention_mask = torch.tensor(\n","        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n","         sorted_indices])\n","    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n","    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n","\n","    return input_ids, attention_mask, token_type_ids, position_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.35127Z","iopub.status.idle":"2022-03-27T13:01:59.351572Z","shell.execute_reply":"2022-03-27T13:01:59.351433Z","shell.execute_reply.started":"2022-03-27T13:01:59.351411Z"},"id":"gZ0l1HparvgZ","trusted":true},"outputs":[],"source":["test_batch_size = 40\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n","                                          shuffle=False, collate_fn=collate_fn_style_test,\n","                                          num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.352637Z","iopub.status.idle":"2022-03-27T13:01:59.352968Z","shell.execute_reply":"2022-03-27T13:01:59.352792Z","shell.execute_reply.started":"2022-03-27T13:01:59.352777Z"},"id":"XoSHTbJUrvgZ","trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    model.eval()\n","    predictions = []\n","    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n","                                                                        desc='Test',\n","                                                                        position=1,\n","                                                                        leave=None):\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        token_type_ids = token_type_ids.to(device)\n","        position_ids = position_ids.to(device)\n","\n","        output = model(input_ids=input_ids,\n","                       attention_mask=attention_mask,\n","                       token_type_ids=token_type_ids,\n","                       position_ids=position_ids)\n","\n","        logits = output.logits\n","        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n","        predictions += batch_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.354216Z","iopub.status.idle":"2022-03-27T13:01:59.354537Z","shell.execute_reply":"2022-03-27T13:01:59.354392Z","shell.execute_reply.started":"2022-03-27T13:01:59.35437Z"},"id":"tGO3aS-VrvgZ","trusted":true},"outputs":[],"source":["test_df['Category'] = predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:01:59.355517Z","iopub.status.idle":"2022-03-27T13:01:59.355792Z","shell.execute_reply":"2022-03-27T13:01:59.355662Z","shell.execute_reply.started":"2022-03-27T13:01:59.355647Z"},"id":"VndXxal3rvgZ","trusted":true},"outputs":[],"source":["test_df.to_csv('submission.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
